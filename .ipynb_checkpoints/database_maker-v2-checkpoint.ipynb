{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066b413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, text, inspect, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06580e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9621f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of folders containing the CSV files\n",
    "folders = ['./Resources/arefin_data', './Resources/ellis_data', './Resources/rita_data', './Resources/uwagboe_data']\n",
    "\n",
    "# Connect to SQLite database (this will create the file if it doesn't exist)\n",
    "conn = sqlite3.connect('stockdata.sqlite')\n",
    "\n",
    "for folder in folders:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.csv'):\n",
    "            # Read CSV file into DataFrame\n",
    "            df = pd.read_csv(os.path.join(folder, file))\n",
    "            \n",
    "            # Check if 'id' column exists, if not create it\n",
    "            if 'id' not in df.columns:\n",
    "                df.insert(0, 'id', range(1, 1 + len(df)))\n",
    "            \n",
    "            # Use the filename (without .csv) as the table name\n",
    "            table_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Convert DataFrame to SQL table in SQLite database\n",
    "            df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b164672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we retrieve the data from the database\n",
    "engine = create_engine(\"sqlite:///stockdata.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534aa8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arefin\\AppData\\Local\\Temp\\ipykernel_6236\\1158962484.py:4: SADeprecationWarning: The AutomapBase.prepare.reflect parameter is deprecated and will be removed in a future release.  Reflection is enabled when AutomapBase.prepare.autoload_with is passed.\n",
      "  Base.prepare(engine, reflect=True) # Use the Base class to reflect the database tables\n"
     ]
    }
   ],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base() # Declare a Base using `automap_base()`\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True) # Use the Base class to reflect the database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc46407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# View all of the classes that automap found\n",
    "print(Base.classes.keys()) # Print all of the classes mapped to the Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0704e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "engine = create_engine(\"sqlite:///stockdata.sqlite\")\n",
    "# Use the inspector to get the table names\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "print(table_names)\n",
    "\n",
    "# conn = engine.connect()\n",
    "# result = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# tables = result.fetchall()\n",
    "# print(tables)\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('./Resources/S&P500companies.csv')\n",
    "\n",
    "# 2. Rename some columns\n",
    "df = df.rename(columns={'Symbol':'Ticker','Security':'Company','GICS Sub-Industry': 'Sub_sector', 'Headquarters Location': 'Headquarters'})\n",
    "\n",
    "# 3. Delete some columns \n",
    "df = df.drop(columns=['GICS Sector', 'CIK'])\n",
    "\n",
    "# 4. Construct the dictionaries\n",
    "metadata = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the resulting dictionary to verify\n",
    "# print(data_dict)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Acquire the Records\n",
    "set0 = pd.read_csv('./Resources/ellis_data/AAPL.csv')\n",
    "set1 = pd.read_csv('./Resources/ellis_data/AMZN.csv')\n",
    "set2 = pd.read_csv('./Resources/ellis_data/GOOGL.csv')\n",
    "set3 = pd.read_csv('./Resources/ellis_data/META.csv')\n",
    "set4 = pd.read_csv('./Resources/ellis_data/MSFT.csv')\n",
    "set5 = pd.read_csv('./Resources/ellis_data/NDVA.csv')\n",
    "set6 = pd.read_csv('./Resources/ellis_data/TSLA.csv')\n",
    "#------------\n",
    "set7 = pd.read_csv('./Resources/uwagboe_data/DXC.csv')\n",
    "set8 = pd.read_csv('./Resources/uwagboe_data/FFIV.csv')\n",
    "set9 = pd.read_csv('./Resources/uwagboe_data/JNPR.csv')\n",
    "set10 = pd.read_csv('./Resources/uwagboe_data/QRVO.csv')\n",
    "set11 = pd.read_csv('./Resources/uwagboe_data/SEDG.csv')\n",
    "#------------\n",
    "set12 = pd.read_csv('./Resources/arefin_data/ANSS-Ansys_monthly_5yrs.csv')\n",
    "set13 = pd.read_csv('./Resources/arefin_data/GE-General Electric_monthly_5yrs.csv')\n",
    "set14 = pd.read_csv('./Resources/arefin_data/HPE-Hawlett Packard_monthly_5yrs.csv')\n",
    "set15 = pd.read_csv('./Resources/arefin_data/KEYS-Keysight Holdings_monthly_5yrs.csv')\n",
    "set16 = pd.read_csv('./Resources/arefin_data/MTD-Mettler Toledo_monthly_5yrs.csv')\n",
    "set17 = pd.read_csv('./Resources/arefin_data/ZBH-Zimmer Biomet Holdings_monthly_5yrs.csv')\n",
    "\n",
    "df_sets = [\"set\" + str(i) for i in range(18)]\n",
    "\n",
    "tickers = [\"Select All\",\"AAPL\",\"AMZN\",\"GOOGL\",\"META\",\"MSFT\",\"NVDA\",\"TSLA\",\"DXC\",\"FFIV\",\"JNPR\",\"QRVO\",\"SEDG\",\"ANSS\",\"GE\",\"HPE\",\"KEYS\",\"MTD\",\"ZBH\"] # df[\"Ticker\"].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8493e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(globals()[df_sets[0]])[\"Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[df_sets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_records = []\n",
    "for cdf, ts in zip(df_sets, tickers):\n",
    "    company_record={\n",
    "        \"ticker\":ts,\n",
    "        \"dates\":(globals()[cdf])[\"Date\"].tolist(),\n",
    "        \"open\": (globals()[cdf])[\"Open\"].tolist(),\n",
    "        \"high\": (globals()[cdf])[\"High\"].tolist(),\n",
    "        \"low\": (globals()[cdf])[\"Low\"].tolist(),\n",
    "        \"close\": (globals()[cdf])[\"Close\"].tolist(),\n",
    "        \"adj close\": (globals()[cdf])[\"Adj Close\"].tolist(),\n",
    "        \"volume\": (globals()[cdf])[\"Volume\"].tolist()\n",
    "    }\n",
    "    stock_records.append(company_record)\n",
    "\n",
    "final_dataset = {\"tickers\":tickers,\n",
    "                 \"company_info\":metadata,\n",
    "                 \"stock_history\": stock_records,\n",
    "                }\n",
    "\n",
    "print(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "final_dataset = {\n",
    "    \"tickers\": tickers,\n",
    "    \"company_info\": metadata,\n",
    "    \"stock_history\": stock_records\n",
    "}\n",
    "\n",
    "# Save the final_dataset as a JSON file\n",
    "with open('final_dataset.json', 'w') as json_file:\n",
    "    json.dump(final_dataset, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c1e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
